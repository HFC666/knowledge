## 统计模型

统计模型是用来模拟或近似数据生成的过程。

贝叶斯统计中的三个重要组成部分：

+ 先验
+ 似然
+ 后验

关于分册模型，我们看之前讲过的一个例子：

假设
$$
y_i|\mu,\sigma^2\sim \mathrm{N}(\mu,\sigma^2)
$$

$$
\mu|\sigma^2\sim \mathrm{N}(\mu_0,\frac{\sigma^2}{w_0})
$$

$$
\sigma^2\sim \Gamma^{-1}(\nu_0,\beta_0)
$$

那么我们的联合概率分布可以写为：
$$
\begin{aligned}
p(y_1,\cdots,y_n,\mu,\sigma^2) &= p(y_1,\cdots,p_n|\mu,\sigma^2)p(\mu|\sigma^2)p(\sigma^2)\\
&=\prod_{i=1}^n\left[\mathrm{N}(y_i|\mu,\sigma^2)\right]\times \mathrm{N}(\mu|\mu_0,\frac{\sigma^2}{w_0})\times \Gamma^{-1}(\sigma^2|\nu_0,\beta_0)\\
&\propto p(\mu,\sigma^2|y_1,\cdots,y_n)
\end{aligned}
$$

### 常见的概率分布

#### 离散

##### 均匀分布

$$
X\sim \operatorname{Uniform}(N)
$$

$$
P(X=x|N) = 1/N,x = 1,2,\cdots,N
$$

$$
\mathrm{E}[X] = \frac{N+1}{2}
$$

$$
\operatorname{Var}[X] = \frac{N^2-1}{12}
$$

##### 伯努利分布

$$
X\sim \operatorname{Bern}(p)
$$

$$
P(X=x|p) = p^x(1-p)^{1-x},x=0,1
$$

$$
\mathrm{E}[X] = p
$$

$$
\operatorname{Var}[X] = p(1-p)
$$

##### 二项分布

$$
Y\sim \operatorname{Binom}(n,p)
$$

$$
P(Y=y|n,p) = C_n^pp^y(1-p)^{n-y}
$$

$$
\mathrm{E}[Y] = np
$$

$$
\operatorname{Var} = np(1-p)
$$

##### 泊松分布

泊松分布主要用来计数。参数$\lambda>0$是我们期望观察到我们正在计数的事物的比率。
$$
X\sim \operatorname{Pois}(\lambda)
$$

$$
P(X=x|\lambda) = \frac{\lambda^x\exp(-\lambda)}{x!}
$$

$$
\mathrm{E}[X] = \lambda
$$

$$
\operatorname{Var}[X] = \lambda
$$

##### 几何分布

指的是在达到成功时的失败的次数。
$$
X\sim \operatorname{Geo}(p)
$$

$$
P(X=x|p) = p(1-p)^x
$$

$$
\mathrm{E}[X] = \frac{1-p}{p}
$$

##### 负二项分布

是对几何分布的推广，指的是在达到$r$次成功时失败的次数。
$$
Y\sim \operatorname{NegBinom}(r,p)
$$

$$
P(Y=y|r,p) = C_{r+y-1}^yp^r(1-p)^y
$$

$$
\mathrm{E}[Y] = \frac{r(1-p)}{p}
$$

$$
\operatorname{Var}[Y] = \frac{r(1-p)}{p^2}
$$

##### 多项式分布

为二项分布的推广，有$k$中结果，第$k$个结果出现$x_k$次，出现的概率为$p_k$。
$$
f(x_1,\cdots,x_k|p_1,\cdots,p_k) = \frac{n!}{x_1!\cdots x_k!}p^{x_1}\cdots p^{x_k}
$$

#### 连续

##### 均匀分布

$$
X\sim \operatorname{Uniform}(a,b)
$$

$$
f(x|a,b) = \frac{1}{b-a}I_{\{a\le x\le b\}}
$$

$$
\mathrm{E}[X] = \frac{a+b}{2}
$$

$$
\operatorname{Var}[X] = \frac{(b-a)^2}{12}
$$

##### Beta

$$
X\sim \operatorname{Beta}(\alpha,\beta)
$$

$$
f(x|\alpha,\beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}I_{\{0<x<1\}}
$$

$$
\mathrm{E}[X] = \frac{\alpha}{\alpha+\beta}
$$

$$
\operatorname{Var}[X] = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
$$

##### 指数分布

指数分布常用来对随机事件之间的等待时间进行建模。
$$
X\sim \operatorname{Exp}(\lambda)
$$

$$
f(x|\lambda) = \lambda e^{-\lambda x}I_{\{x\ge0\}}
$$

$$
\mathrm{E}[X] = \frac{1}{\lambda}
$$

$$
\operatorname{Var}[X] = \frac{1}{\lambda^2}
$$

##### 双指数分布

是指数分布的推广，可以取负数。
$$
X\sim \operatorname{DExp}(\lambda)
$$

$$
f(x|\mu,\tau) = \frac{\tau}{2}e^{-\tau|x-\mu|}
$$

$$
\mathrm{E}[X] = \mu
$$

$$
\operatorname{Var}[X] = \frac{1}{2\tau^2}
$$

##### Gamma

当$X_1,X_2,\cdots,X_n$是相继的事件之间的等待时间，$n$个事件总的等待时间$Y = \sum_{i=1}^n X_i$将服从shape参数$\alpha=n$，rate参数$\beta=\lambda$的Gamma分布。
$$
Y\sim \operatorname{Gamma}(\alpha,\beta)
$$

$$
f(y|\alpha,\beta) = \frac{\beta^\alpha}{\Gamma(\alpha)}y^{\alpha-1}e^{-\beta y}I_{y\ge 0}
$$

$$
\mathrm{E}[Y]=\frac{\alpha}{\beta}
$$

$$
\operatorname{Var}[Y] = \frac{\alpha}{\beta^2}
$$

> $$
> \Gamma(n)=(n-1)!
> $$

##### Inverse-Gamma

当$X\sim \operatorname{Gamma}(\alpha,\beta)$，随机变量$Y=1/X\sim \operatorname{Inverse-Gamma}(\alpha,\beta)$，其中
$$
f(y) = \frac{\beta^\alpha}{\Gamma(\alpha)}y^{-(\alpha+1)}\exp\left(-\frac{\beta}{y}\right)I_{\{y>0\}}
$$

$$
\mathrm{E}(Y) = \frac{\beta}{\alpha-1}
$$

##### t

如果我们有正态分布数据。我们易得：
$$
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim \mathrm{N}(0,1)
$$
但是我们可能不知道$\sigma$的值。我们用$S = \sqrt{\sum_{i}(X_i-\bar{X})^2/(n-1)}$来代替他，这就是自由度$\nu=n-1$的$t$分布。
$$
Y\sim t_{\nu}
$$

$$
f(y) = \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\sqrt{\nu\pi}}\left(1+\frac{y^2}{\nu}\right)^{-\frac{\nu+1}{2}}
$$

$$
\mathrm{E}[Y] = 0 \text{ if }\nu>1
$$

$$
\operatorname{Var}[Y] = \frac{\nu}{\nu-2}\text{ if }\nu>2
$$

##### Dirichlet

当似然函数为多项式分布时，Dirichlet分布是共轭的：
$$
f(y_1,y_2,\cdots,y_K|\alpha_1,\alpha_2,\cdots,\alpha_K) = \frac{\Gamma(\sum_{k=1}^K\alpha_k)}{\prod_{k=1}^K\Gamma(\alpha_k)}\cdot p_1^{\alpha_1-1}\cdot p_2^{\alpha_2-1}\cdots  p_K^{\alpha_K-1}
$$

### 蒙特卡洛估计

#### 蒙特卡洛积分

假设我们有函数$h(\theta)$，则其期望为
$$
\mathrm{E}[h(\theta)] = \int h(\theta)p(\theta)d\theta \approx \frac{1}{m}\sum_{i=1}^m h(\theta_i)
$$
下面看一个例子：

假设$h(\theta)=I_{\theta<5}(\theta)$，则
$$
\begin{aligned}
\mathrm{E}(h(\theta))&= \int_0^\infty I_{\theta<5}(\theta)p(\theta)d\theta\\
&= \int_0^51\cdot p(\theta)d\theta\\
&=\Pr[0< \theta <5]\\
&\approx \frac{1}{m}\sum_{i=1}^mI_{\theta<5}(\theta)
\end{aligned}
$$
所以可以用出现在$(0,5)$之间的样本比例来近似在此区间的概率。

#### 蒙特卡洛误差

根据中心极限定理，我们知道：
$$
\bar{\theta}\sim \mathrm{N}(\mathrm{E}(\theta),\frac{\operatorname{Var}(\theta)}{m})
$$
我们用样本方差来估计$\operatorname{Var}(\theta)$，我们知道总体方差的无偏估计为：
$$
\hat{\operatorname{Var}}(\theta) = \frac{1}{m-1}\sum_{i=1}^m(\theta_i-\bar{\theta})^2
$$
则
$$
\sqrt{\frac{\hat{\operatorname{Var}(\theta)}}{m}} = \text{standard error}
$$
为蒙特卡洛误差。



假设有分层模型：
$$
y|\phi\sim \operatorname{Bin}(10,\phi)
$$

$$
\phi\sim \operatorname{Beta}(2,2)
$$

我们需要根据联合分布$p(y,\theta)=p(\theta|\phi)p(\phi)$来产生数据。我们可以根据以下步骤生成数据：

1. 从Beta分布中生成数据$\phi_i$
2. 在给定$\phi_i$的条件下生成$y_i^\star\sim \operatorname{Bin}(10,\phi)$

这样就生成了独立的样本$(y_i,\phi_i)$。这种采样让边缘化更加简单，若按照以往，我们需要对联合概率分布进行积分，将$\phi$积分消去后得到边缘分布再对$y$采样，但是现在我们只需要忽略掉样本中的$\phi$即可，将$y_i$视为从其边缘分布采样得到的。

想了一下这就是**吉布斯采样**。:clap:

~~~R
# 我们用上节课提到的例子

# 随机数种子
set.seed(32)

# 样本数
m <- 10000

# 参数
a <- 2.0
b <- 1.0 / 3.0

# 采样
theta <- rgamma(n=m, shape = a, rate = b)

hist(theta, freq = FALSE)

curve(dgamma(x, shape = a, rate = b), col="blue", add = TRUE)

# 我们可以估计其期望
mean(theta)  
# 真实的期望为a / b

# 也可以估计其方差
var(theta)
# 真实的方差为a / b^2

# 我们也可以用来估计其他的参数，比如theta<5的概率
ind <- theta < 5
mean(ind)
# 我们用pgamma函数计算真实值
pgamma(q = 5.0, shape = a, rate = b)

# 我们也可以计算其90%分位数
quantile(theta, probs = 0.9)
# 真实值通过qgamma函数计算
qgamma(p=0.9, shape = a, rate = b)

# 下面看我们之前举的分层模型的例子
m <- 1e5
phi <- rbeta(m, shape1 = 2.0, shape2 = 2.0)
y <- rbinom(m, size = 10, prob = phi)
~~~

